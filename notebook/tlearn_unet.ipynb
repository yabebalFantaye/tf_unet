{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boilerplate code\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys, cv2\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import glob\n",
    "\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "sys.path.append('/home/yfantaye/DeepCount/TFFRCNN')\n",
    "\n",
    "from lib.networks.factory import get_network\n",
    "from lib.fast_rcnn.config import cfg\n",
    "from lib.fast_rcnn.test import im_detect\n",
    "#from lib.fast_rcnn.nmms_wrapper import nms\n",
    "from lib.utils.timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../unet_models/00/model.cpkt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class parse_args():\n",
    "    gpu_id=0\n",
    "    cpu_mode=False\n",
    "    demo_net='VGGnet_test'\n",
    "    model='../unet_models/00/model.cpkt'\n",
    "    model_sax25='../unet_models/40/model.cpkt'\n",
    "    model_sax50='../unet_models/60/model.cpkt'\n",
    "    \n",
    "args = parse_args()\n",
    "args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#REF:\n",
    "# https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc\n",
    "# http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/\n",
    "def freeze_graph(model_folder):\n",
    "    # We retrieve our checkpoint fullpath\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_folder)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "    \n",
    "    # We precise the file fullname of our freezed graph\n",
    "    absolute_model_folder = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_folder + \"/frozen_model.pb\"\n",
    "\n",
    "    # Before exporting our graph, we need to precise what is our output node\n",
    "    # This is how TF decides what part of the Graph he has to keep and what part it can dump\n",
    "    # NOTE: this variable is plural, because you can have multiple output nodes\n",
    "    output_node_names = \"Accuracy/predictions\"\n",
    "\n",
    "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
    "    clear_devices = True\n",
    "    \n",
    "    # We import the meta graph and retrieve a Saver\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "    # We retrieve the protobuf graph definition\n",
    "    graph = tf.get_default_graph()\n",
    "    input_graph_def = graph.as_graph_def()\n",
    "\n",
    "    # We start a session and restore the graph weights\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "\n",
    "        # We use a built-in TF helper to export variables to constants\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "            sess, # The session is used to retrieve the weights\n",
    "            input_graph_def, # The graph_def is used to retrieve the nodes \n",
    "            output_node_names.split(\",\") # The output node names are used to select the usefull nodes\n",
    "        ) \n",
    "\n",
    "        # Finally we serialize and dump the output graph to the filesystem\n",
    "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "            \n",
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we can use again a convenient built-in function to import a graph_def into the \n",
    "    # current default Graph\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def, \n",
    "            input_map=None, \n",
    "            return_elements=None, \n",
    "            name=\"prefix\", \n",
    "            op_dict=None, \n",
    "            producer_op_list=None\n",
    "        )\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "def use_frozen_model(frozen_model_filename):\n",
    "    # We use our \"load_graph\" function\n",
    "    graph = load_graph(frozen_model_filename)\n",
    "\n",
    "    # We can verify that we can access the list of operations in the graph\n",
    "    for op in graph.get_operations():\n",
    "        print(op.name)\n",
    "        # prefix/Placeholder/inputs_placeholder\n",
    "        # ...\n",
    "        # prefix/Accuracy/predictions\n",
    "        \n",
    "    # We access the input and output nodes \n",
    "    x = graph.get_tensor_by_name('prefix/Placeholder/inputs_placeholder:0')\n",
    "    y = graph.get_tensor_by_name('prefix/Accuracy/predictions:0')\n",
    "        \n",
    "    # We launch a Session\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        # Note: we didn't initialize/restore anything, everything is stored in the graph_def\n",
    "        y_out = sess.run(y, feed_dict={\n",
    "            x: [[3, 5, 7, 4, 5, 1, 1, 1, 1, 1]] # < 45\n",
    "        })\n",
    "        print(y_out) # [[ False ]] Yay, it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and displaying the model graph\n",
    "The pretrained network can be downloaded here. Unpack the tensorflow_inception_graph.pb file from the archive and set its path to model_fn variable. Alternatively you can uncomment and run the following cell to download the network:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
